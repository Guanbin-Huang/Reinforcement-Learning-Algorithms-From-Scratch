{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_world(length, width,path_lenght,holes_number,Random_State):\n",
    "    \n",
    "    random.seed(Random_State)\n",
    "    #store all cells in a list\n",
    "    Grid_Cells = []\n",
    "    for row in range(length):\n",
    "        for col in range(width):\n",
    "            Grid_Cells.append([row,col])\n",
    "\n",
    "\n",
    "    #specify the number of holes in the gridworld\n",
    "    \n",
    "    #specify the start point as a random cell\n",
    "    start = [random.randint(0, length), random.randint(0, width)]\n",
    "\n",
    "    #create a path from start point\n",
    "    \"\"\"instead of defining start and goal points,\n",
    "      we define just a start point and a random path with a random lenght to\n",
    "       another point and name it as goal point\"\"\"\n",
    "    \n",
    "    def random_path(Start, Path_Lenght,length, width):\n",
    "        \n",
    "        Path = []\n",
    "        Path.append(Start)\n",
    "        for i in range(Path_Lenght):\n",
    "            \n",
    "            #there are two moves that take us on a random cell named Goal [1,0], [0,1]\n",
    "            \n",
    "            move = random.choice([[1,0], [0,1]])\n",
    "            \n",
    "            #update the start cell/point by the above move\n",
    "            Start = [x + y for x, y in zip(Start, move)]\n",
    "            \n",
    "            #if the movement take us out of our gridworld, we reverse the change in the start point\n",
    "            if Start[0] < 0 or Start[1] < 0 or Start[0] > length-1 or Start[1] > width-1:\n",
    "\n",
    "                Start = [x - y for x, y in zip(Start, move)]\n",
    "\n",
    "            else:\n",
    "                \n",
    "                #create a path history\n",
    "                Path.append(Start)\n",
    "\n",
    "        Goal = Start\n",
    "\n",
    "        return Goal,Path\n",
    "    \n",
    "\n",
    "    GoalPath = random_path(start, path_lenght,length, width)\n",
    "\n",
    "    goal = GoalPath[0]\n",
    "    path = GoalPath[1]\n",
    "\n",
    "    #now we must eliminate the path cells from the Grid_Cells to choose hole cells from remaining cells\n",
    "\n",
    "    FreeCells = [x for x in Grid_Cells if x not in path]\n",
    "\n",
    "    Holes = random.sample(FreeCells, holes_number)\n",
    "\n",
    "    #Also, we can visualize our gridworld in a simple way\n",
    "\n",
    "    def mark_holes(holes):\n",
    "        marked_data = [[\"Hole\" if [row, col] in holes else [row, col] for col in range(width)] for row in range(length)]\n",
    "        return marked_data\n",
    "    \n",
    "    marked_matrix = mark_holes(Holes)\n",
    "\n",
    "    print(tabulate(marked_matrix, tablefmt=\"grid\"))\n",
    "\n",
    "    \n",
    "    return length, width, start, goal, Holes, path,Grid_Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+\n",
      "| Hole   | [0, 1] | [0, 2] | [0, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| [1, 0] | [1, 1] | [1, 2] | [1, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| Hole   | [2, 1] | [2, 2] | [2, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| Hole   | [3, 1] | Hole   | [3, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| [4, 0] | [4, 1] | [4, 2] | [4, 3] |\n",
      "+--------+--------+--------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " 4,\n",
       " [1, 2],\n",
       " [4, 3],\n",
       " [[2, 0], [3, 2], [3, 0], [0, 0]],\n",
       " [[1, 2], [1, 3], [2, 3], [3, 3], [4, 3]],\n",
       " [[0, 0],\n",
       "  [0, 1],\n",
       "  [0, 2],\n",
       "  [0, 3],\n",
       "  [1, 0],\n",
       "  [1, 1],\n",
       "  [1, 2],\n",
       "  [1, 3],\n",
       "  [2, 0],\n",
       "  [2, 1],\n",
       "  [2, 2],\n",
       "  [2, 3],\n",
       "  [3, 0],\n",
       "  [3, 1],\n",
       "  [3, 2],\n",
       "  [3, 3],\n",
       "  [4, 0],\n",
       "  [4, 1],\n",
       "  [4, 2],\n",
       "  [4, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = generate_grid_world(5, 4,4,4,39)\n",
    "environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_distribution(grid_size,randomness):\n",
    "    #random.seed(40)\n",
    "    \n",
    "    #by this function we generate probabilities which their sum is equal to 1\n",
    "    def generate_probabilities(n):\n",
    "\n",
    "        numbers = [random.random() for _ in range(n)]\n",
    "        total_sum = sum(numbers)\n",
    "        scaled_numbers = [num / total_sum for num in numbers]\n",
    "        \n",
    "        return scaled_numbers\n",
    "    \n",
    "    cells_prob = {}\n",
    "    if randomness == 'stochastic':\n",
    "        for cell in range(grid_size):\n",
    "            \n",
    "            #we set the number of probs to 4 due to 4 possible action for each cell (go to its neighbors)\n",
    "            probs = generate_probabilities(4)\n",
    "\n",
    "            cells_prob[cell] = probs\n",
    "    elif randomness == 'equal probable':\n",
    "\n",
    "        for cell in range(grid_size):\n",
    "\n",
    "            cells_prob[cell] = [0.25,0.25,0.25,0.25]\n",
    "    \n",
    "    elif randomness == 'deterministic':\n",
    "        for cell in range(grid_size):\n",
    "\n",
    "            cells_prob[cell] = [0.03,0.06,0.01,0.9] #[0,0,0,1] ##[0.15,.15,0.1,0.6]\n",
    "\n",
    "\n",
    "    #Note that we consider the correspondence between probabilities and actions as below:\n",
    "    #probs = [p1, p2, p3, p4] ---> [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "    return cells_prob\n",
    "\n",
    "def neighbor_cells(cell):\n",
    "\n",
    "    grid_cells = environment[6]\n",
    "    Actions = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "    Neighbors = []\n",
    "    Actions_Neighbors = []\n",
    "    for action in Actions:\n",
    "\n",
    "        neighbor = [x + y for x, y in zip(cell, action)]\n",
    "        #if neighbor not in environment[4]:\n",
    "        Neighbors.append(neighbor)\n",
    "        Actions_Neighbors.append(action)\n",
    "\n",
    "    return Neighbors, Actions_Neighbors\n",
    "\n",
    "#Note\n",
    "\"\"\"As we want to use monte carlo method for estimating the state values\n",
    "   it has been assumed that we have not any knowledge about the environment.\n",
    "   Therefore, we should consider the transitions into the holes cells\n",
    "   (against the case of policy iteration)\"\"\"\n",
    "\n",
    "def arbitrary_policy(randomness):\n",
    "    #random.seed(randomness)\n",
    "    \n",
    "    policy = {}\n",
    "    policy_action = {}\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state not in environment[4]:\n",
    "\n",
    "            neighbors = neighbor_cells(state)[0]\n",
    "            Actions_Neighbors = neighbor_cells(state)[1]\n",
    "\n",
    "            allowed_positions = []\n",
    "\n",
    "            for neighbor in neighbors:\n",
    "                \n",
    "                if neighbor in environment[6] and neighbor not in environment[4]:\n",
    "                    \n",
    "                    allowed_positions.append(neighbor)\n",
    "        \n",
    "            next_state = random.choice(allowed_positions)\n",
    "\n",
    "            row = next_state[0] - state[0]\n",
    "            col = next_state[1] - state[1]\n",
    "            PolicyAction = [row, col]\n",
    "\n",
    "            policy['{}'.format(state)] = next_state\n",
    "            policy_action['{}'.format(state)] = PolicyAction\n",
    "\n",
    "\n",
    "    return policy, policy_action\n",
    "\n",
    "state_indice_dict = {}\n",
    "counter = 0\n",
    "for state in environment[6]:\n",
    "\n",
    "    state = str(state)\n",
    "    state_indice_dict[state] = counter\n",
    "    counter = counter + 1\n",
    "\n",
    "def generate_trajectory(policy,randomness):\n",
    "\n",
    "    policy_action = policy[1]\n",
    "\n",
    "    probs = probability_distribution(environment[0]*environment[1],'stochastic')\n",
    "    \n",
    "    start = environment[2]\n",
    "\n",
    "    terminate = start\n",
    "\n",
    "    trajectory = [start]\n",
    "    c = 0\n",
    "    test = []\n",
    "    while terminate != environment[3]:\n",
    "        random.seed(randomness+c)\n",
    "        Actions = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "        action = policy_action[str(terminate)]\n",
    "        Actions.remove(action)\n",
    "        #sorted_actions = [action]\n",
    "        sorted_actions = Actions + [action]\n",
    "        #print(sorted_actions)\n",
    "        state_indice = state_indice_dict[str(terminate)]\n",
    "        actions_prob = probs[state_indice]\n",
    "        actions_prob.sort()\n",
    "        #print(actions_prob)\n",
    "        #print(actions_prob)\n",
    "\n",
    "\n",
    "        selected_action = random.choices(sorted_actions, actions_prob)[0]\n",
    "        \n",
    "\n",
    "        \"\"\"if c==0:\n",
    "           print(sorted_actions)\n",
    "           print(actions_prob)\n",
    "           print(selected_action)\n",
    "           test.append(selected_action)\"\"\"\n",
    "        \n",
    "        next_state = [x + y for x, y in zip(terminate, selected_action)]\n",
    "        \n",
    "        #if the agent goes out of the gridworld, it stays in its current state\n",
    "        if next_state not in environment[6]:\n",
    "\n",
    "            next_state = terminate\n",
    "        \n",
    "        #if it drops into the holes, it goes to the start points\n",
    "        elif next_state in environment[4]:\n",
    "\n",
    "            next_state = start\n",
    "\n",
    "        \n",
    "        terminate = next_state\n",
    "\n",
    "        trajectory.append(terminate)\n",
    "        c = c+1\n",
    "\n",
    "    return trajectory #,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[0, 1]': [0, 2],\n",
       "  '[0, 2]': [0, 1],\n",
       "  '[0, 3]': [0, 2],\n",
       "  '[1, 0]': [1, 1],\n",
       "  '[1, 1]': [2, 1],\n",
       "  '[1, 2]': [1, 3],\n",
       "  '[1, 3]': [1, 2],\n",
       "  '[2, 1]': [3, 1],\n",
       "  '[2, 2]': [2, 3],\n",
       "  '[2, 3]': [3, 3],\n",
       "  '[3, 1]': [4, 1],\n",
       "  '[3, 3]': [2, 3],\n",
       "  '[4, 0]': [4, 1],\n",
       "  '[4, 1]': [4, 2],\n",
       "  '[4, 2]': [4, 3],\n",
       "  '[4, 3]': [4, 2]},\n",
       " {'[0, 1]': [0, 1],\n",
       "  '[0, 2]': [0, -1],\n",
       "  '[0, 3]': [0, -1],\n",
       "  '[1, 0]': [0, 1],\n",
       "  '[1, 1]': [1, 0],\n",
       "  '[1, 2]': [0, 1],\n",
       "  '[1, 3]': [0, -1],\n",
       "  '[2, 1]': [1, 0],\n",
       "  '[2, 2]': [0, 1],\n",
       "  '[2, 3]': [1, 0],\n",
       "  '[3, 1]': [1, 0],\n",
       "  '[3, 3]': [-1, 0],\n",
       "  '[4, 0]': [0, 1],\n",
       "  '[4, 1]': [0, 1],\n",
       "  '[4, 2]': [0, 1],\n",
       "  '[4, 3]': [0, -1]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_0 = arbitrary_policy(41)\n",
    "policy_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [3, 1],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [4, 0],\n",
       " [4, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [3, 3],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [0, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [0, 3],\n",
       " [0, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [3, 1],\n",
       " [4, 1],\n",
       " [4, 0],\n",
       " [1, 2],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [1, 2],\n",
       " [2, 2],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_0 = arbitrary_policy(41)\n",
    "trjcty = generate_trajectory(policy_0,1)\n",
    "trjcty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trjcty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:03<00:00, 15.80it/s]\n"
     ]
    }
   ],
   "source": [
    "policy_0 = arbitrary_policy(41)\n",
    "\n",
    "a = []\n",
    "test = []\n",
    "for i in tqdm(range(1000)):\n",
    "    trjcty = generate_trajectory(policy_0,i)\n",
    "    test.append(trjcty[1])\n",
    "    #print(i)\n",
    "    \n",
    "    #a.append(trjcty)\n",
    "\n",
    "    #if len(trjcty) != 763:\n",
    "    #    print(len(trjcty))\n",
    "    \n",
    "    #if i > 1 and a[i] != a[i-1]:\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "#c = set(a)\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-visit MC prediction, for estimationg $V \\approx v_{\\pi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_reward(policy,state):\n",
    "\n",
    "    policy_state = policy[0]\n",
    "    \n",
    "    next_state = policy_state[str(state)]\n",
    "\n",
    "    if next_state in environment[4]:\n",
    "\n",
    "        r = -3\n",
    "    \n",
    "    elif next_state == environment[3]:\n",
    "\n",
    "        r = 10\n",
    "    \n",
    "    else:\n",
    "\n",
    "        r = -1\n",
    "    \n",
    "    return r\n",
    "\n",
    "#Note that here we want to evaluate just a fixed policy\n",
    "# and so we are not trying to optimize it \n",
    "def monte_carlo_prediction(num_trials, policy, gamma):\n",
    "\n",
    "    #V = np.zeros((environment[6],1))\n",
    "\n",
    "    #store returns of each trajectory\n",
    "    Returns = {} #np.zeros((environment[6],1))\n",
    "    Lens = []\n",
    "    #Loop for ever (for each episode)\n",
    "    for trial in tqdm(range(num_trials)):\n",
    "        \n",
    "        #generate an episode\n",
    "        trajectory = generate_trajectory(policy,trial)\n",
    "        Lens.append(trajectory)\n",
    "\n",
    "        #limit the lenght of trajectory\n",
    "\n",
    "        #total reward\n",
    "        G = 0\n",
    "\n",
    "        trajectory.reverse()\n",
    "        \n",
    "        \n",
    "        returns = {}\n",
    "\n",
    "        for state in environment[6]:\n",
    "            \n",
    "            if state not in environment[4] and state != environment[3]:\n",
    "\n",
    "                returns[str(state)] = 0\n",
    "\n",
    "        first_visit = []\n",
    "        for step in trajectory[1:]:\n",
    "\n",
    "            if step not in first_visit:\n",
    "\n",
    "                first_visit.append(step)\n",
    "\n",
    "                r = state_reward(policy)\n",
    "\n",
    "                G = gamma * G + r\n",
    "\n",
    "                returns[str(step)] = returns[str(step)] + G\n",
    "        \n",
    "        #Returns[trial] = returns\n",
    "    \n",
    "    V = {}\n",
    "    for step in list(returns.keys()):\n",
    "\n",
    "        V[step] = returns[step]/num_trials\n",
    "    \n",
    "\n",
    "    return V,returns #, Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [06:25<00:00, 259.52it/s]\n"
     ]
    }
   ],
   "source": [
    "x = monte_carlo_prediction(100000,policy_0,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': -8.12579511e-05,\n",
       " '[0, 2]': -8.313215599e-05,\n",
       " '[0, 3]': -8.481894039099999e-05,\n",
       " '[1, 0]': -5.6953279000000005e-05,\n",
       " '[1, 1]': -5.2170310000000005e-05,\n",
       " '[1, 2]': -3.439e-05,\n",
       " '[1, 3]': -2.7099999999999998e-05,\n",
       " '[2, 1]': -4.6855900000000007e-05,\n",
       " '[2, 2]': -4.0951e-05,\n",
       " '[2, 3]': -1.8999999999999998e-05,\n",
       " '[3, 1]': -8.63370463519e-05,\n",
       " '[3, 3]': -1e-05,\n",
       " '[4, 0]': -8.770334171670999e-05,\n",
       " '[4, 1]': -8.8933007545039e-05,\n",
       " '[4, 2]': -0.0001100397067905351}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': -8.12579511,\n",
       " '[0, 2]': -8.313215599,\n",
       " '[0, 3]': -8.481894039099998,\n",
       " '[1, 0]': -5.6953279000000006,\n",
       " '[1, 1]': -5.217031,\n",
       " '[1, 2]': -3.439,\n",
       " '[1, 3]': -2.71,\n",
       " '[2, 1]': -4.68559,\n",
       " '[2, 2]': -4.0951,\n",
       " '[2, 3]': -1.9,\n",
       " '[3, 1]': -8.63370463519,\n",
       " '[3, 3]': -1.0,\n",
       " '[4, 0]': -8.770334171671,\n",
       " '[4, 1]': -8.8933007545039,\n",
       " '[4, 2]': -11.00397067905351}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-policy first-visit MC control (for $\\epsilon$-soft policies), estimates ${\\pi} \\approx {\\pi}_{*} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_action_reward(policy,state):\n",
    "\n",
    "    policy_state = policy[0]\n",
    "    \n",
    "    next_state = policy_state[str(state)]\n",
    "\n",
    "    if next_state in environment[4]:\n",
    "\n",
    "        r = -3\n",
    "    \n",
    "    elif next_state == environment[3]:\n",
    "\n",
    "        r = 10\n",
    "    \n",
    "    else:\n",
    "\n",
    "        r = -1\n",
    "    \n",
    "    return r\n",
    "    \n",
    "\n",
    "def derive_action(current_state, next_state):\n",
    "\n",
    "    row = next_state[0] - current_state[0]\n",
    "    col = next_state[1] - current_state[1]\n",
    "    action = [row, col]\n",
    "\n",
    "    return action\n",
    "\n",
    "def generate_trajectory_probability_based(policy,randomness,epsilon):\n",
    "\n",
    "    \n",
    "    probs = probability_distribution(environment[0]*environment[1],'stochastic')  \n",
    "    start = environment[2]\n",
    "    terminate = start\n",
    "    trajectory = [start]\n",
    "    c = 0\n",
    "    test = []\n",
    "    while terminate != environment[3]:\n",
    "        random.seed(randomness+c)\n",
    "        Actions = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "        #we have two probabilities for epsilon-greedy action selection\n",
    "        #It's a kind of exploration-exploitation balancing\n",
    "        \n",
    "        #probability for exploration on not best action values\n",
    "        low_prob = epsilon/len(Actions)\n",
    "        high_prob = 1 - epsilon + (epsilon/len(Actions))\n",
    "\n",
    "        #this random action selection is for balancing exploration-exploitation trade-off\n",
    "\n",
    "        exex_probs = [low_prob,low_prob,low_prob,high_prob]\n",
    "        if type(policy) == tuple:\n",
    "            policy = policy[1]\n",
    "        \n",
    "        best_action_value = policy[str(terminate)]\n",
    "        print(best_action_value)\n",
    "        Actions_copy = Actions.copy()\n",
    "        print(Actions_copy)\n",
    "        Actions_copy.remove(best_action_value)\n",
    "        exex_actions = Actions_copy + [best_action_value]\n",
    "        \n",
    "        action = random.choices(exex_actions, exex_probs)[0]\n",
    "\n",
    "        #second part of action selection\n",
    "        Actions.remove(action)\n",
    "        sorted_actions = Actions + [action]\n",
    "        state_indice = state_indice_dict[str(terminate)]\n",
    "        actions_prob = probs[state_indice]\n",
    "        actions_prob.sort()\n",
    "        #this random action selection is due to the randomness of the environment\n",
    "        selected_action = random.choices(sorted_actions, actions_prob)[0]\n",
    "        next_state = [x + y for x, y in zip(terminate, selected_action)]\n",
    "        #if the agent goes out of the gridworld, it stays in its current state\n",
    "        if next_state not in environment[6]:\n",
    "            next_state = terminate\n",
    "        #if it drops into the holes, it goes to the start points\n",
    "        elif next_state in environment[4]:\n",
    "            next_state = start\n",
    "        terminate = next_state\n",
    "        trajectory.append(terminate)\n",
    "        c = c+1\n",
    "\n",
    "    return trajectory\n",
    "\n",
    "\"\"\"In this function, trials (averaging) and improving policy are sone at the same time.\n",
    "   At each trial, the q function (here a dictionary) computed and a better policy created.\n",
    "   The next trial generate a new trajectory, based on new better policy that obtained the last trial.\"\"\"\n",
    "def OnPolicy_MC_prediction(num_trials, policy, gamma, epsilon):\n",
    "\n",
    "    def reverse_dictionary(dict):\n",
    "\n",
    "        reverse_dict = {}\n",
    "        \n",
    "        counter = 0\n",
    "        for key in list(dict.keys()):\n",
    "\n",
    "            val = dict[key]\n",
    "\n",
    "            reverse_dict[val] = key\n",
    "        \n",
    "        return reverse_dict\n",
    "\n",
    "    #store returns of each trajectory\n",
    "    Returns = {} #np.zeros((environment[6],1))\n",
    "    Lens = []\n",
    "    \n",
    "    #Loop for ever (for each episode)\n",
    "    for trial in tqdm(range(num_trials)):\n",
    "        \n",
    "        #generate an episode\n",
    "        trajectory = generate_trajectory_probability_based(policy,trial,epsilon)\n",
    "        Lens.append(trajectory)\n",
    "\n",
    "        #limit the lenght of trajectory\n",
    "\n",
    "        #total reward\n",
    "        G = 0\n",
    "\n",
    "        trajectory.reverse()\n",
    "        \n",
    "        returns = {}\n",
    "        for i in range(len(trajectory[1:-1])):\n",
    "\n",
    "            step = trajectory[1:][i]\n",
    "\n",
    "            returns[str(step)] = {}\n",
    "\n",
    "            for action in [\"[1,0]\",\"[-1,0]\",\"[0,1]\",\"[0,-1]\"]:\n",
    "\n",
    "                returns[str(step)][action] = 0\n",
    "\n",
    "\n",
    "        for state in environment[6]:\n",
    "            \n",
    "            if state not in environment[4] and state != environment[3]:\n",
    "\n",
    "                for action in [\"[1,0]\",\"[-1,0]\",\"[0,1]\",\"[0,-1]\"]:\n",
    "\n",
    "                    returns[str(step)][action] = 0\n",
    "\n",
    "        first_visit = []\n",
    "        for i in range(len(trajectory[1:-1])):\n",
    "\n",
    "            step = trajectory[1:-1][i]\n",
    "\n",
    "            if step not in first_visit:\n",
    "\n",
    "                first_visit.append(step)\n",
    "\n",
    "                #if step != environment[2]:\n",
    "\n",
    "                action = derive_action(trajectory[1:-1][i+1],trajectory[1:-1][i])\n",
    "                #else:\n",
    "\n",
    "\n",
    "                r = state_action_reward(policy,step)\n",
    "\n",
    "                G = gamma * G + r\n",
    "\n",
    "                #returns[(str(step),str(action))] = returns[str(step),str(action)] + G\n",
    "                print(str(step),str(action))\n",
    "                returns[str(step)][str(action)] = returns[str(step)][str(action)] + G\n",
    "\n",
    "        #Returns[trial] = returns\n",
    "    \n",
    "        Q = {}\n",
    "\n",
    "        for state in environment[6]:\n",
    "\n",
    "                Q[str(state)] = {}\n",
    "        #pair=(step,action)\n",
    "        for state in list(returns.keys()):\n",
    "\n",
    "            for action in [\"[1,0]\",\"[-1,0]\",\"[0,1]\",\"[0,-1]\"]:\n",
    "\n",
    "                Q[str(state)][action] = returns[str(state)][action]/trial\n",
    "\n",
    "        policy = {}\n",
    "        for state in list(Q.keys()):\n",
    "\n",
    "            value_action_state = reverse_dictionary(Q[state])\n",
    "            Max_val = max(list(value_action_state.keys()))\n",
    "            best_action = value_action_state[Max_val]\n",
    "\n",
    "            policy[state] = best_action\n",
    "        \n",
    "\n",
    "    return policy,Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_action_reward(policy,state):\n",
    "\n",
    "    if type(policy) == tuple:\n",
    "        \n",
    "        policy_state = policy[0]\n",
    "    \n",
    "    else:\n",
    "        policy_state = policy\n",
    "\n",
    "    \n",
    "    \n",
    "    next_state = policy_state[str(state)]\n",
    "\n",
    "    if next_state in environment[4]:\n",
    "\n",
    "        r = -3\n",
    "    \n",
    "    elif next_state == environment[3]:\n",
    "\n",
    "        r = 100\n",
    "    \n",
    "    else:\n",
    "\n",
    "        r = -1\n",
    "    \n",
    "    return r\n",
    "    \n",
    "\n",
    "def derive_action(current_state, next_state):\n",
    "\n",
    "    row = next_state[0] - current_state[0]\n",
    "    col = next_state[1] - current_state[1]\n",
    "    action = [row, col]\n",
    "\n",
    "    return action\n",
    "\n",
    "def generate_trajectory_probability_based(policy,randomness,epsilon,traj_len):\n",
    "\n",
    "    \n",
    "    probs = probability_distribution(environment[0]*environment[1],'deterministic')  \n",
    "    start = environment[2]\n",
    "    terminate = start\n",
    "    trajectory = [start]\n",
    "    c = 0\n",
    "    test = []\n",
    "    while terminate != environment[3]:\n",
    "        random.seed(randomness+c)\n",
    "        Actions = [[1, 0],[-1, 0],[0, 1],[0, -1]]\n",
    "\n",
    "        #we have two probabilities for epsilon-greedy action selection\n",
    "        #It's a kind of exploration-exploitation balancing\n",
    "        \n",
    "        #probability for exploration on not best action values\n",
    "        low_prob = epsilon/len(Actions)\n",
    "        high_prob = 1 - epsilon #+ (epsilon/len(Actions))\n",
    "\n",
    "        #this random action selection is for balancing exploration-exploitation trade-off\n",
    "\n",
    "        exex_probs = [low_prob,low_prob,low_prob,high_prob]\n",
    "        if type(policy) == tuple:\n",
    "            policy = policy[1]\n",
    "        \n",
    "        best_action_value = policy[str(terminate)]\n",
    "        #print(type(best_action_value))\n",
    "        Actions_copy = Actions.copy()\n",
    "        #print(Actions_copy)\n",
    "        Actions_copy.remove(best_action_value)\n",
    "        exex_actions = Actions_copy + [best_action_value]\n",
    "        #print(exex_actions)\n",
    "        #print(exex_probs)\n",
    "        \n",
    "        action = random.choices(exex_actions, exex_probs)[0]\n",
    "\n",
    "        #second part of action selection\n",
    "        Actions.remove(action)\n",
    "        sorted_actions = Actions + [action]\n",
    "        state_indice = state_indice_dict[str(terminate)]\n",
    "        actions_prob = probs[state_indice]\n",
    "        actions_prob.sort()\n",
    "\n",
    "        #print(sorted_actions)\n",
    "        #print(actions_prob)\n",
    "        #this random action selection is due to the randomness of the environment\n",
    "        selected_action = random.choices(sorted_actions, actions_prob)[0]\n",
    "        #print(selected_action)\n",
    "        #print('=====')\n",
    "        next_state = [x + y for x, y in zip(terminate, selected_action)]\n",
    "        #if the agent goes out of the gridworld, it stays in its current state\n",
    "        if next_state not in environment[6]:\n",
    "            next_state = terminate\n",
    "        #if it drops into the holes, it goes to the start points\n",
    "        elif next_state in environment[4]:\n",
    "            next_state = start\n",
    "        terminate = next_state\n",
    "        trajectory.append(terminate)\n",
    "        c = c+1\n",
    "\n",
    "        if c >traj_len:\n",
    "            break\n",
    "            c = traj_len + 1\n",
    "    \n",
    "    if c > traj_len:\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        return trajectory\n",
    "    \n",
    "\n",
    "def OnPolicy_MC_prediction(num_trials, policy, gamma, epsilon,traj_len):\n",
    "    \n",
    "    def reverse_dictionary(dict):\n",
    "        reverse_dict = {}\n",
    "        for key in list(dict.keys()):\n",
    "            val = dict[key]\n",
    "            reverse_dict[val] = key\n",
    "        return reverse_dict\n",
    "\n",
    "    Q = {}\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state not in environment[4]:\n",
    "            \n",
    "            Q[str(state)] = {}\n",
    "\n",
    "            for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "\n",
    "                #next_state = [x + y for x, y in zip(state, ast.literal_eval(action))]\n",
    "\n",
    "                #if (next_state in environment[6]) and next_state not in environment[4]:\n",
    "                    \n",
    "                Q[str(state)][action] = random.uniform(1e-9, 1e-8)\n",
    "    \n",
    "    counter = {}\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state not in environment[4]:\n",
    "            \n",
    "            counter[str(state)] = {}\n",
    "\n",
    "            for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "\n",
    "                #next_state = [x + y for x, y in zip(state, ast.literal_eval(action))]\n",
    "\n",
    "                #if (next_state in environment[6]) and next_state not in environment[4]:\n",
    "                    \n",
    "                counter[str(state)][action] = random.uniform(1e-9, 1e-8)\n",
    "    \n",
    "    done_trials = 0\n",
    "    Policies = []\n",
    "    for trial in tqdm(range(1,num_trials)):\n",
    "        #print(policy['[3,3]'])\n",
    "        trajectory = generate_trajectory_probability_based(policy, trial, epsilon,traj_len)\n",
    "        #print(len(trajectory))\n",
    "\n",
    "        #if len(trajectory) < 100:\n",
    "        #print(trajectory)\n",
    "        \n",
    "        if trajectory:\n",
    "            #print(len(trajectory))\n",
    "\n",
    "            done_trials +=1 \n",
    "        \n",
    "\n",
    "            G = 0\n",
    "            returns = {}\n",
    "            first_visit = []\n",
    "\n",
    "            for state in environment[6]:\n",
    "\n",
    "                if state not in environment[4]:# and state != environment[3]:\n",
    "\n",
    "                    returns[str(state)] = {}\n",
    "\n",
    "            for state in environment[6]:\n",
    "                \n",
    "                if state not in environment[4]:# and state != environment[3]:\n",
    "\n",
    "                    for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "\n",
    "                        #next_state = [x + y for x, y in zip(state, ast.literal_eval(action))]\n",
    "\n",
    "                        #if (next_state in environment[6]) and next_state not in environment[4]:\n",
    "\n",
    "                        returns[str(state)][action] = random.uniform(1e-9, 1e-8)\n",
    "\n",
    "                \n",
    "            #print(returns)\n",
    "\n",
    "            for i in range(len(trajectory[1:])):\n",
    "                step = trajectory[1:][i]\n",
    "\n",
    "                if step not in first_visit:\n",
    "                    \n",
    "                    \"\"\"state_str = str(step)\n",
    "                    if state_str not in returns:\n",
    "                        returns[state_str] = {}\n",
    "                        for action in [\"[1,0]\", \"[-1,0]\", \"[0,1]\", \"[0,-1]\"]:\n",
    "                            returns[state_str][action] = 0\"\"\"  # Initialize all actions with value 0\n",
    "                            \n",
    "                    first_visit.append(step)\n",
    "                    #action = derive_action(trajectory[1:][i + 1], trajectory[1:][i])\n",
    "                    last_step = str(trajectory[1:][i])\n",
    "                    if type(policy) == tuple:\n",
    "                        policy = policy[1]\n",
    "                        \n",
    "                    action = policy[last_step]\n",
    "                    #if action == [0,0]:\n",
    "                    r = state_action_reward(policy, step)\n",
    "                    G = gamma * G + r\n",
    "                    print(G)\n",
    "                    #action_str = str(action)\n",
    "                    #print(action_str)\n",
    "                    #print(returns[str(step)])\n",
    "                    returns[str(step)][str(action)] += G\n",
    "                    #print(returns[str(step)][action_str])\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            for state in list(returns.keys()):\n",
    "                for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "                    #print(state,action)\n",
    "                    #print('q',Q[state][action])\n",
    "                    #print(returns[state][action])\n",
    "                    #if returns[state][\"[-1, 0]\"] != 0:\n",
    "                    #    print(returns[state][\"[-1, 0]\"])\n",
    "                    #Q[state][action] = returns[state][action] / trial\n",
    "\n",
    "                    if returns[state][action] > 1e-3:\n",
    "\n",
    "                        counter[state][action] = counter[state][action] + 1\n",
    "\n",
    "                        Q[state][action] = Q[state][action] + returns[state][action]\n",
    "\n",
    "                        Q[state][action] = Q[state][action] / round(counter[state][action])\n",
    "                        #print('f')\n",
    "                    \n",
    "                    #else:\n",
    "\n",
    "                    #    Q[state][action] = Q[state][action] + returns[state][action]\n",
    "\n",
    "            policy = {}\n",
    "            for state in list(Q.keys()):\n",
    "                #print('d')\n",
    "                if Q[state] != {}:\n",
    "                    value_action_state = reverse_dictionary(Q[state])\n",
    "                    #print('value_action_state:',value_action_state)\n",
    "                    #print(state)\n",
    "                    #print(value_action_state)\n",
    "                    Max_val = max(list(value_action_state.keys()))\n",
    "                    best_action = value_action_state[Max_val]\n",
    "                    policy[state] = ast.literal_eval(best_action)\n",
    "            #print(policy)\n",
    "            #if policy != policy_0:\n",
    "            #    print('f')\n",
    "\n",
    "            Policies.append(policy)\n",
    "    \n",
    "        \n",
    "    return policy, Q,done_trials,Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 41/4999 [00:00<00:24, 202.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n",
      "-4.0951\n",
      "-4.68559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1414/4999 [00:07<00:16, 213.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n",
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2173/4999 [00:10<00:13, 203.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3527/4999 [00:17<00:06, 213.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4422/4999 [00:21<00:02, 213.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.9\n",
      "-2.71\n",
      "-3.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4999/4999 [00:24<00:00, 206.30it/s]\n"
     ]
    }
   ],
   "source": [
    "#deterministic\n",
    "policy_0 = arbitrary_policy(41)\n",
    "first_try = OnPolicy_MC_prediction(5000, policy_0, 0.9, 0.1,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_try[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': [-1, 0],\n",
       " '[0, 2]': [-1, 0],\n",
       " '[0, 3]': [0, 1],\n",
       " '[1, 0]': [0, 1],\n",
       " '[1, 1]': [0, -1],\n",
       " '[1, 2]': [0, 1],\n",
       " '[1, 3]': [-1, 0],\n",
       " '[2, 1]': [0, 1],\n",
       " '[2, 2]': [0, 1],\n",
       " '[2, 3]': [-1, 0],\n",
       " '[3, 1]': [1, 0],\n",
       " '[3, 3]': [-1, 0],\n",
       " '[4, 0]': [0, -1],\n",
       " '[4, 1]': [0, 1],\n",
       " '[4, 2]': [0, -1],\n",
       " '[4, 3]': [1, 0]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_try[3][101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_try[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': [0, 1],\n",
       " '[0, 2]': [0, 1],\n",
       " '[0, 3]': [1, 0],\n",
       " '[1, 0]': [0, -1],\n",
       " '[1, 1]': [0, -1],\n",
       " '[1, 2]': [0, -1],\n",
       " '[1, 3]': [-1, 0],\n",
       " '[2, 1]': [0, -1],\n",
       " '[2, 2]': [0, 1],\n",
       " '[2, 3]': [0, -1],\n",
       " '[3, 1]': [0, 1],\n",
       " '[3, 3]': [0, 1],\n",
       " '[4, 0]': [1, 0],\n",
       " '[4, 1]': [0, -1],\n",
       " '[4, 2]': [0, 1],\n",
       " '[4, 3]': [1, 0]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_try[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': {'[1, 0]': 2.7839816536871657e-09,\n",
       "  '[-1, 0]': 4.070388438423737e-09,\n",
       "  '[0, 1]': 5.623526489235524e-09,\n",
       "  '[0, -1]': 5.364479147886709e-09},\n",
       " '[0, 2]': {'[1, 0]': 2.75089434895555e-09,\n",
       "  '[-1, 0]': 6.399461394519876e-09,\n",
       "  '[0, 1]': 7.801231553066807e-09,\n",
       "  '[0, -1]': 2.1118841408766913e-09},\n",
       " '[0, 3]': {'[1, 0]': 8.599671410291494e-09,\n",
       "  '[-1, 0]': 5.91911327017657e-09,\n",
       "  '[0, 1]': 3.549700207999323e-09,\n",
       "  '[0, -1]': 3.1172338335052286e-09},\n",
       " '[1, 0]': {'[1, 0]': 4.601580426131289e-09,\n",
       "  '[-1, 0]': 7.026366854686743e-09,\n",
       "  '[0, 1]': 4.893445000390407e-09,\n",
       "  '[0, -1]': 7.423178413404856e-09},\n",
       " '[1, 1]': {'[1, 0]': 4.651492675138199e-09,\n",
       "  '[-1, 0]': 4.338016676874158e-09,\n",
       "  '[0, 1]': 1.6342256937969212e-09,\n",
       "  '[0, -1]': 7.326327960386075e-09},\n",
       " '[1, 2]': {'[1, 0]': 4.89293845525448e-09,\n",
       "  '[-1, 0]': 1.6399543880724184e-09,\n",
       "  '[0, 1]': 2.9454914494729664e-09,\n",
       "  '[0, -1]': 6.178578875305891e-09},\n",
       " '[1, 3]': {'[1, 0]': 8.503077937721205e-09,\n",
       "  '[-1, 0]': 9.298784072906369e-09,\n",
       "  '[0, 1]': 2.0841902141711434e-09,\n",
       "  '[0, -1]': 1.1722103974304277e-09},\n",
       " '[2, 1]': {'[1, 0]': 3.135747294809156e-09,\n",
       "  '[-1, 0]': 3.3435710474527666e-09,\n",
       "  '[0, 1]': 2.517214707468909e-09,\n",
       "  '[0, -1]': 7.899798161520413e-09},\n",
       " '[2, 2]': {'[1, 0]': 1.885522549613318e-09,\n",
       "  '[-1, 0]': 5.480969594686223e-09,\n",
       "  '[0, 1]': 9.618832656263245e-09,\n",
       "  '[0, -1]': 4.69494490762516e-09},\n",
       " '[2, 3]': {'[1, 0]': 8.678992288905038e-09,\n",
       "  '[-1, 0]': 6.650518130998715e-09,\n",
       "  '[0, 1]': 6.600313860227383e-09,\n",
       "  '[0, -1]': 8.94903398872554e-09},\n",
       " '[3, 1]': {'[1, 0]': 2.0402657735647617e-09,\n",
       "  '[-1, 0]': 6.937912407350211e-09,\n",
       "  '[0, 1]': 8.085961626525834e-09,\n",
       "  '[0, -1]': 4.353884630817661e-09},\n",
       " '[3, 3]': {'[1, 0]': 6.897924810622122e-09,\n",
       "  '[-1, 0]': 2.105404628067109e-09,\n",
       "  '[0, 1]': 9.507522344228005e-09,\n",
       "  '[0, -1]': 9.410846135510483e-09},\n",
       " '[4, 0]': {'[1, 0]': 9.215852861043253e-09,\n",
       "  '[-1, 0]': 6.046736585564385e-09,\n",
       "  '[0, 1]': 7.484002922573417e-09,\n",
       "  '[0, -1]': 4.3134299663073265e-09},\n",
       " '[4, 1]': {'[1, 0]': 1.912737403404008e-09,\n",
       "  '[-1, 0]': 8.914845737782716e-09,\n",
       "  '[0, 1]': 8.196324832979946e-09,\n",
       "  '[0, -1]': 9.328559283803594e-09},\n",
       " '[4, 2]': {'[1, 0]': 7.48590729415686e-09,\n",
       "  '[-1, 0]': 2.3945480126424977e-09,\n",
       "  '[0, 1]': 7.818109443081199e-09,\n",
       "  '[0, -1]': 6.272972140017902e-09},\n",
       " '[4, 3]': {'[1, 0]': 6.352238476297816e-09,\n",
       "  '[-1, 0]': 1.8821155285557954e-09,\n",
       "  '[0, 1]': 5.4858595041182644e-09,\n",
       "  '[0, -1]': 4.585764282255189e-09}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_try[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4999/4999 [32:49<00:00,  2.54it/s]  \n"
     ]
    }
   ],
   "source": [
    "policy_0 = arbitrary_policy(41)\n",
    "first_try = OnPolicy_MC_prediction(5000, policy_0, 0.9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
