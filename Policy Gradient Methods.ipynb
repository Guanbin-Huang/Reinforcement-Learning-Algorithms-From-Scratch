{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_world(length, width,path_lenght,holes_number,Random_State):\n",
    "    \n",
    "    random.seed(Random_State)\n",
    "    #store all cells in a list\n",
    "    Grid_Cells = []\n",
    "    for row in range(length):\n",
    "        for col in range(width):\n",
    "            Grid_Cells.append([row,col])\n",
    "\n",
    "\n",
    "    #specify the number of holes in the gridworld\n",
    "    \n",
    "    #specify the start point as a random cell\n",
    "    start = [random.randint(0, length), random.randint(0, width)]\n",
    "\n",
    "    #create a path from start point\n",
    "    \"\"\"instead of defining start and goal points,\n",
    "      we define just a start point and a random path with a random lenght to\n",
    "       another point and name it as goal point\"\"\"\n",
    "    \n",
    "    def random_path(Start, Path_Lenght,length, width):\n",
    "        \n",
    "        Path = []\n",
    "        Path.append(Start)\n",
    "        for i in range(Path_Lenght):\n",
    "            \n",
    "            #there are two moves that take us on a random cell named Goal [1,0], [0,1]\n",
    "            \n",
    "            move = random.choice([[1,0], [0,1]])\n",
    "            \n",
    "            #update the start cell/point by the above move\n",
    "            Start = [x + y for x, y in zip(Start, move)]\n",
    "            \n",
    "            #if the movement take us out of our gridworld, we reverse the change in the start point\n",
    "            if Start[0] < 0 or Start[1] < 0 or Start[0] > length-1 or Start[1] > width-1:\n",
    "\n",
    "                Start = [x - y for x, y in zip(Start, move)]\n",
    "\n",
    "            else:\n",
    "                \n",
    "                #create a path history\n",
    "                Path.append(Start)\n",
    "\n",
    "        Goal = Start\n",
    "\n",
    "        return Goal,Path\n",
    "    \n",
    "\n",
    "    GoalPath = random_path(start, path_lenght,length, width)\n",
    "\n",
    "    goal = GoalPath[0]\n",
    "    path = GoalPath[1]\n",
    "\n",
    "    #now we must eliminate the path cells from the Grid_Cells to choose hole cells from remaining cells\n",
    "\n",
    "    FreeCells = [x for x in Grid_Cells if x not in path]\n",
    "\n",
    "    Holes = random.sample(FreeCells, holes_number)\n",
    "\n",
    "    #Also, we can visualize our gridworld in a simple way\n",
    "\n",
    "    def mark_holes(holes):\n",
    "        marked_data = [[\"Hole\" if [row, col] in holes else [row, col] for col in range(width)] for row in range(length)]\n",
    "        return marked_data\n",
    "    \n",
    "    marked_matrix = mark_holes(Holes)\n",
    "\n",
    "    print(tabulate(marked_matrix, tablefmt=\"grid\"))\n",
    "\n",
    "    \n",
    "    return length, width, start, goal, Holes, path,Grid_Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+\n",
      "| Hole   | [0, 1] | [0, 2] | [0, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| [1, 0] | [1, 1] | [1, 2] | [1, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| Hole   | [2, 1] | [2, 2] | [2, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| Hole   | [3, 1] | Hole   | [3, 3] |\n",
      "+--------+--------+--------+--------+\n",
      "| [4, 0] | [4, 1] | [4, 2] | [4, 3] |\n",
      "+--------+--------+--------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " 4,\n",
       " [1, 2],\n",
       " [4, 3],\n",
       " [[2, 0], [3, 2], [3, 0], [0, 0]],\n",
       " [[1, 2], [1, 3], [2, 3], [3, 3], [4, 3]],\n",
       " [[0, 0],\n",
       "  [0, 1],\n",
       "  [0, 2],\n",
       "  [0, 3],\n",
       "  [1, 0],\n",
       "  [1, 1],\n",
       "  [1, 2],\n",
       "  [1, 3],\n",
       "  [2, 0],\n",
       "  [2, 1],\n",
       "  [2, 2],\n",
       "  [2, 3],\n",
       "  [3, 0],\n",
       "  [3, 1],\n",
       "  [3, 2],\n",
       "  [3, 3],\n",
       "  [4, 0],\n",
       "  [4, 1],\n",
       "  [4, 2],\n",
       "  [4, 3]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#environment = generate_grid_world(50, 40,1300,400,39)\n",
    "environment = generate_grid_world(5, 4,4,4,39)\n",
    "\n",
    "environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_distribution(grid_size,randomness):\n",
    "    #random.seed(40)\n",
    "    \n",
    "    #by this function we generate probabilities which their sum is equal to 1\n",
    "    def generate_probabilities(n):\n",
    "\n",
    "        numbers = [random.random() for _ in range(n)]\n",
    "        total_sum = sum(numbers)\n",
    "        scaled_numbers = [num / total_sum for num in numbers]\n",
    "        \n",
    "        return scaled_numbers\n",
    "    \n",
    "    cells_prob = {}\n",
    "    if randomness == 'stochastic':\n",
    "        for cell in range(grid_size):\n",
    "            \n",
    "            #we set the number of probs to 4 due to 4 possible action for each cell (go to its neighbors)\n",
    "            probs = generate_probabilities(4)\n",
    "\n",
    "            cells_prob[cell] = probs\n",
    "    elif randomness == 'equal probable':\n",
    "\n",
    "        for cell in range(grid_size):\n",
    "\n",
    "            cells_prob[cell] = [0.25,0.25,0.25,0.25]\n",
    "    \n",
    "    elif randomness == 'deterministic':\n",
    "        for cell in range(grid_size):\n",
    "\n",
    "            cells_prob[cell] = [0.03,0.06,0.01,0.9] #[0,0,0,1] ##[0.15,.15,0.1,0.6]\n",
    "\n",
    "\n",
    "    #Note that we consider the correspondence between probabilities and actions as below:\n",
    "    #probs = [p1, p2, p3, p4] ---> [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "    return cells_prob\n",
    "\n",
    "def neighbor_cells(cell):\n",
    "\n",
    "    grid_cells = environment[6]\n",
    "    Actions = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "    Neighbors = []\n",
    "    Actions_Neighbors = []\n",
    "    for action in Actions:\n",
    "\n",
    "        neighbor = [x + y for x, y in zip(cell, action)]\n",
    "        #if neighbor not in environment[4]:\n",
    "        Neighbors.append(neighbor)\n",
    "        Actions_Neighbors.append(action)\n",
    "\n",
    "    return Neighbors, Actions_Neighbors\n",
    "\n",
    "def arbitrary_policy(randomness):\n",
    "\n",
    "        #random.seed(randomness)\n",
    "        \n",
    "    policy = {}\n",
    "    policy_action = {}\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state not in environment[4]:\n",
    "\n",
    "            neighbors = neighbor_cells(state)[0]\n",
    "            Actions_Neighbors = neighbor_cells(state)[1]\n",
    "\n",
    "            allowed_positions = []\n",
    "\n",
    "            for neighbor in neighbors:\n",
    "                \n",
    "                if neighbor in environment[6] and neighbor not in environment[4]:\n",
    "                    \n",
    "                    allowed_positions.append(neighbor)\n",
    "            \n",
    "            if len(allowed_positions) > 0:\n",
    "                \n",
    "                next_state = random.choice(allowed_positions)\n",
    "                row = next_state[0] - state[0]\n",
    "                col = next_state[1] - state[1]\n",
    "                PolicyAction = [row, col]\n",
    "\n",
    "                policy['{}'.format(state)] = next_state\n",
    "                policy_action['{}'.format(state)] = PolicyAction\n",
    "\n",
    "\n",
    "\n",
    "    return policy, policy_action\n",
    "\n",
    "def state_reward(next_state):\n",
    "\n",
    "    if next_state in environment[4]:\n",
    "\n",
    "        r = -3\n",
    "    \n",
    "    elif next_state == environment[3]:\n",
    "\n",
    "        r = 10\n",
    "    \n",
    "    elif next_state not in environment[6]:\n",
    "\n",
    "        r = -2\n",
    "    \n",
    "    else:\n",
    "\n",
    "        r = -1\n",
    "    \n",
    "    return r\n",
    "\n",
    "def reverse_dictionary(dict):\n",
    "    reverse_dict = {}\n",
    "    for key in list(dict.keys()):\n",
    "        val = dict[key]\n",
    "        reverse_dict[val] = key\n",
    "    return reverse_dict\n",
    "\n",
    "\n",
    "state_indice_dict = {}\n",
    "counter = 0\n",
    "for state in environment[6]:\n",
    "\n",
    "    state = str(state)\n",
    "    state_indice_dict[state] = counter\n",
    "    counter = counter + 1\n",
    "\n",
    "def generate_trajectory(policy,randomness,environment_stochasticity):\n",
    "\n",
    "    policy_action = policy[1]\n",
    "    probs = probability_distribution(environment[0]*environment[1],environment_stochasticity)\n",
    "    start = environment[2]\n",
    "    terminate = start\n",
    "    trajectory = []\n",
    "    pure_trajectory = [start]\n",
    "    c = 0\n",
    "    while terminate != environment[3]:\n",
    "        random.seed(randomness+c)\n",
    "        Actions = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "        action = policy_action[str(terminate)]\n",
    "        Actions.remove(action)\n",
    "        sorted_actions = Actions + [action]\n",
    "        state_indice = state_indice_dict[str(terminate)]\n",
    "        actions_prob = probs[state_indice]\n",
    "        actions_prob.sort()\n",
    "\n",
    "        selected_action = random.choices(sorted_actions, actions_prob)[0]\n",
    "        current_state = terminate\n",
    "        next_state = [x + y for x, y in zip(terminate, selected_action)]\n",
    "        pure_trajectory.append(next_state)\n",
    "        \n",
    "        #if the agent goes out of the gridworld, it stays in its current state\n",
    "        if next_state not in environment[6]:\n",
    "            next_state = terminate\n",
    "        \n",
    "        #if it drops into the holes, it goes to the start points\n",
    "        elif next_state in environment[4]:\n",
    "            next_state = start  \n",
    "\n",
    "        terminate = next_state\n",
    "        trajectory.append((current_state))\n",
    "        c = c+1\n",
    "    \n",
    "    trajectory.append((environment[3]))\n",
    "    pure_trajectory.append(environment[3])\n",
    "\n",
    "    return trajectory,pure_trajectory\n",
    "\n",
    "def extract_features(state):\n",
    "\n",
    "    goal = environment[3]\n",
    "    max_length = environment[0]\n",
    "    max_width = environment[1]\n",
    "\n",
    "    w1 = (goal[0] - state[0]) / max_width\n",
    "    w2 = (goal[1] - state[1]) / max_length\n",
    "\n",
    "    return abs(w1), abs(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_theta(environment):\n",
    "    \n",
    "    policy = {}\n",
    "    policy_action = {}\n",
    "\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state != environment[3] and state not in environment[4]:\n",
    "\n",
    "            Neighbors = neighbor_cells(state)\n",
    "\n",
    "            Distances = {}\n",
    "\n",
    "            for neighbor in Neighbors[0]:\n",
    "\n",
    "                if neighbor not in environment[4] and neighbor in environment[6]:\n",
    "\n",
    "                    distance = np.cos(extract_features(neighbor)[0]+extract_features(neighbor)[1])\n",
    "                    Distances[distance] = neighbor\n",
    "            \n",
    "            #closest to the terminate state\n",
    "            if list(Distances.keys()) != []:\n",
    "\n",
    "                best_neighbor = Distances[max(list(Distances.keys()))]\n",
    "            \n",
    "            else:\n",
    "                best_neighbor = state\n",
    "\n",
    "            policy[str(state)] = best_neighbor\n",
    "\n",
    "            row = best_neighbor[0] - state[0]\n",
    "            col = best_neighbor[1] - state[1]\n",
    "            PolicyAction = [row,col]\n",
    "            policy_action[str(state)] = PolicyAction\n",
    "    \n",
    "\n",
    "    return policy, policy_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'[0, 1]': [1, 1],\n",
       "  '[0, 2]': [1, 2],\n",
       "  '[0, 3]': [1, 3],\n",
       "  '[1, 0]': [1, 1],\n",
       "  '[1, 1]': [2, 1],\n",
       "  '[1, 2]': [2, 2],\n",
       "  '[1, 3]': [2, 3],\n",
       "  '[2, 1]': [3, 1],\n",
       "  '[2, 2]': [2, 3],\n",
       "  '[2, 3]': [3, 3],\n",
       "  '[3, 1]': [4, 1],\n",
       "  '[3, 3]': [4, 3],\n",
       "  '[4, 0]': [4, 1],\n",
       "  '[4, 1]': [4, 2],\n",
       "  '[4, 2]': [4, 3]},\n",
       " {'[0, 1]': [1, 0],\n",
       "  '[0, 2]': [1, 0],\n",
       "  '[0, 3]': [1, 0],\n",
       "  '[1, 0]': [0, 1],\n",
       "  '[1, 1]': [1, 0],\n",
       "  '[1, 2]': [1, 0],\n",
       "  '[1, 3]': [1, 0],\n",
       "  '[2, 1]': [1, 0],\n",
       "  '[2, 2]': [0, 1],\n",
       "  '[2, 3]': [1, 0],\n",
       "  '[3, 1]': [1, 0],\n",
       "  '[3, 3]': [1, 0],\n",
       "  '[4, 0]': [0, 1],\n",
       "  '[4, 1]': [0, 1],\n",
       "  '[4, 2]': [0, 1]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_theta(environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCCE: Monte-Carlo Policy-Gradient Control (episodic) for $\\pi_{*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 1]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[0, 2]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[0, 3]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[1, 0]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[1, 1]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[1, 2]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[1, 3]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[2, 1]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[2, 2]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[2, 3]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[3, 1]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[3, 3]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[4, 0]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[4, 1]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[4, 2]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]},\n",
       " '[4, 3]': {'[1,0]': [0, 0],\n",
       "  '[-1,0]': [0, 0],\n",
       "  '[0,1]': [0, 0],\n",
       "  '[0,-1]': [0, 0]}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta = {}\n",
    "for state in environment[6]:\n",
    "\n",
    "    if state not in environment[4]:\n",
    "\n",
    "        Theta[str(state)] = {}\n",
    "\n",
    "        for action in [\"[1,0]\",\"[-1,0]\",\"[0,1]\",\"[0,-1]\"]:\n",
    "            \n",
    "            Theta[str(state)][action] = [0,0]\n",
    "\n",
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_policy_gradient(num_trials, gamma,alpha, policy,environment_stochasticity):\n",
    "    \n",
    "    Theta = {}\n",
    "    for state in environment[6]:\n",
    "\n",
    "        if state not in environment[4]:\n",
    "\n",
    "            Theta[str(state)] = {}\n",
    "\n",
    "            for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "                \n",
    "                Theta[str(state)][action] = [0,0] #Features[element] + random.uniform(1e-9, 1e-8)\n",
    "\n",
    "\n",
    "    \n",
    "    for trial in tqdm(range(num_trials)):\n",
    "\n",
    "        TRAJECTORY = generate_trajectory(policy,trial,environment_stochasticity)\n",
    "\n",
    "        trajectory = TRAJECTORY[0]\n",
    "        \n",
    "        G = 0\n",
    "\n",
    "        for step_indx in range(len(trajectory[:-1])):\n",
    "\n",
    "            step = trajectory[step_indx]\n",
    "            next_step = trajectory[step_indx+1]\n",
    "\n",
    "            done_action = [next_step[0] - step[0], next_step[1] - step[1]]\n",
    "\n",
    "            for t in range(step_indx+1,len(trajectory[:-1])):\n",
    "\n",
    "                \n",
    "                step = trajectory[t]\n",
    "                next_step = trajectory[t+1]\n",
    "            \n",
    "                r = state_reward(next_step)\n",
    "\n",
    "                G = G + gamma ** (t - step_indx - 1) * r\n",
    "            #print(G)\n",
    "        \n",
    "        softmax_denominator = 0.0001\n",
    "        for action in [\"[1, 0]\",\"[-1, 0]\",\"[0, 1]\",\"[0, -1]\"]:\n",
    "\n",
    "            print(str(step),str(action))\n",
    "            print(Theta[str(step)][action] , Theta[str(step)][action][1])\n",
    "            print('sin',-np.sin(Theta[str(step)][action][0] + Theta[str(step)][action][1]))\n",
    "            print(Theta[str(step)][action][0] , Theta[str(step)][action][1])\n",
    "            print('exp',math.exp(np.cos(Theta[str(step)][action][0] + Theta[str(step)][action][1])))\n",
    "\n",
    "            softmax_denominator = softmax_denominator +\\\n",
    "                 -np.sin(Theta[str(step)][action][0] + Theta[str(step)][action][1]) *\\\n",
    "             math.exp(np.cos(Theta[str(step)][action][0] + Theta[str(step)][action][1]))\n",
    "\n",
    "        print('softmax_denominators',softmax_denominator)\n",
    "        gradient = (-np.sin(Theta[str(step)][str(done_action)][0] + Theta[str(step)][str(done_action)][1]) *\\\n",
    "        math.exp(np.cos(Theta[str(step)][str(done_action)][0] + Theta[str(step)][str(done_action)][1]))) / softmax_denominator\n",
    "\n",
    "        print('gradient',gradient)\n",
    "            \n",
    "        t1 = Theta[str(step)][str(done_action)] +\\\n",
    "            alpha * gamma ** step_indx * G * gradient\n",
    "\n",
    "        Theta[str(step)][str(done_action)] = [t1,t1]\n",
    "             \n",
    "\n",
    "    \n",
    "\n",
    "    return Theta\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<00:00, 1002.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3] [1, 0]\n",
      "[0, 0] 0\n",
      "sin -0.0\n",
      "0 0\n",
      "exp 2.718281828459045\n",
      "[3, 3] [-1, 0]\n",
      "[0, 0] 0\n",
      "sin -0.0\n",
      "0 0\n",
      "exp 2.718281828459045\n",
      "[3, 3] [0, 1]\n",
      "[0, 0] 0\n",
      "sin -0.0\n",
      "0 0\n",
      "exp 2.718281828459045\n",
      "[3, 3] [0, -1]\n",
      "[0, 0] 0\n",
      "sin -0.0\n",
      "0 0\n",
      "exp 2.718281828459045\n",
      "softmax_denominators 0.0001\n",
      "gradient -0.0\n",
      "[3, 3] [1, 0]\n",
      "[array([0., 0.]), array([0., 0.])] [0. 0.]\n",
      "sin [-0. -0.]\n",
      "[0. 0.] [0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7552\\4136175725.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpi_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmonte_carlo_policy_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'deterministic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7552\\485208758.py\u001b[0m in \u001b[0;36mmonte_carlo_policy_gradient\u001b[1;34m(num_trials, gamma, alpha, policy, environment_stochasticity)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0msoftmax_denominator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_denominator\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "pi_0 = pi_theta(environment)\n",
    "monte_carlo_policy_gradient(500, 0.9,0.5, pi_0,'deterministic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26749882862458735"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos(1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.706655567161391"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(0.534535646745785678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3832037604.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ZimaIT\\AppData\\Local\\Temp\\ipykernel_7552\\3832037604.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    if ''d'' == 'd':\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if ''d'' == 'd':\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
